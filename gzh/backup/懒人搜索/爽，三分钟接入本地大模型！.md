# 爽，三分钟接入本地大模型！

[**返回列表页**](/gzh/懒人搜索)

小懒自动备份，仅供查阅学习

懒人搜索继续分享优质资源软件

![](https://mmbiz.qpic.cn/sz_mmbiz_png/BXJXNRRKQNKdP8mQcfmdFrLZ9xFcvvwricaJGJWKZlnh9qy1Snna8Hvr0Ep68e4kmFsh7eUP1p3jB9IhHey0K5g/640?wx_fmt=png&from;=appmsg)

之前小懒也分享过本地运行的大模型，毕竟是第三方开发的，效果没那么好量化

今天来分享一下，三分钟接入知名大厂的本地大模型！

利用Ollama+Anything LLM，无需写代码，不用Docker环境，甚至不用GPU（当然，有最好），给你电脑赋能AI

小懒会附上软件下载的官网，同时后台准备一份云盘安装包，方便外网环境差的bro下载~

## 本地部署

### 1.Ollama下载安装

Ollama是一个开源框架，专门设计用于在本地运行大型语言模型。

可以理解为一个下载中心，可以直接下载多个大模型

首先访问Ollama官网：https://ollama.com

根据你的电脑平台，点击下载

![](https://mmbiz.qpic.cn/sz_mmbiz_png/BXJXNRRKQNKdP8mQcfmdFrLZ9xFcvvwrKR024bdefl6WU60RRnXemGSSVmppnljhicLPvcRDSqsHVRJQQTPdcWQ/640?wx_fmt=png&from;=appmsg)

下载后，双击exe安装

![](https://mmbiz.qpic.cn/sz_mmbiz_png/BXJXNRRKQNKdP8mQcfmdFrLZ9xFcvvwrQslRbqCs91YG8DicHOibfyTN6gsmDkibZGsD9TMQdNnXqzficfOibfOkmtw/640?wx_fmt=png&from;=appmsg)

安装完后，打开命令行窗口：Win+R，输入CMD

![](https://mmbiz.qpic.cn/sz_mmbiz_png/BXJXNRRKQNKdP8mQcfmdFrLZ9xFcvvwrRdIbCSlGvg2KJAt7onHIZohqUPvwTvNBEibL1GX3HD0PMJKkFeOmjWQ/640?wx_fmt=png&from;=appmsg)

在这里输入`Ollama run qwen2.5`，千问模型是目前中文大模型里排名靠前的存在，其他模型可以自行到Library查看

![](https://mmbiz.qpic.cn/sz_mmbiz_png/BXJXNRRKQNKdP8mQcfmdFrLZ9xFcvvwr07FtduTjPdCib4oHjBCICRg6GLGxVa6hMhQPR6uswAbJeGHictPQzcCA/640?wx_fmt=png&from;=appmsg)

输入上面指令，程序就会自动帮你下载千问2.5模型

![](https://mmbiz.qpic.cn/sz_mmbiz_png/BXJXNRRKQNKdP8mQcfmdFrLZ9xFcvvwrR8DPo9H8uacmkFxCrPOnYOM5j5gPoZwp63Ix88pOs3sdCGUAtZs7Ig/640?wx_fmt=png&from;=appmsg)

默认下载到C盘，不想放C盘的话，下方补充部分AI解答

耐心等待下载即可，下载速度和网速有关，好在国内网络也能下

下载后其实就可以直接AI对话了

这个对话框发送信息就能回答

![](https://mmbiz.qpic.cn/sz_mmbiz_png/BXJXNRRKQNKdP8mQcfmdFrLZ9xFcvvwrvAXvm1ZDRnqshglenUpeN2cZgRpNnxj8NcgmxGjebCMjd632IybsTQ/640?wx_fmt=png&from;=appmsg)

用对话框也太简陋了，我们开启一下后台服务

就能利用Anythin LLM做成API甚至集成知识库

继续在上面的CMD窗口里输入：`ollama serve`，就能开启后台服务

你可以在浏览器访问：`http://127.0.0.1:11434/`

确定一下是不是在运行

![](https://mmbiz.qpic.cn/sz_mmbiz_png/BXJXNRRKQNKdP8mQcfmdFrLZ9xFcvvwrhp1Fkqz0OPicMmwjI2SpavozXZ0eNM0tjAfNsuWZrla1UiaypdLMgHzA/640?wx_fmt=png&from;=appmsg)

### 2.Anything LLM下载安装

结合Anything LLM，我们可以直接在软件里对话，甚至可以把本地知识库和大模型做成API

访问Anything LLM的官网：`https://anythingllm.com/`

下载安装包

![](https://mmbiz.qpic.cn/sz_mmbiz_png/BXJXNRRKQNKdP8mQcfmdFrLZ9xFcvvwrVV9IoaKRBIUW4ndgXToS29Uk7GuVxGuD0TlnS2EzZAVGOXarqDEhxw/640?wx_fmt=png&from;=appmsg)

安装后打开软件，可以看到LLM选择，我们选择Ollama，模型选择qwen2.5

![](https://mmbiz.qpic.cn/sz_mmbiz_png/BXJXNRRKQNKdP8mQcfmdFrLZ9xFcvvwrbOGdp3icib92sOZxu0f1ficib2gkL4XunyRl0WV7Tnz1U8OvLQWFb2klFw/640?wx_fmt=png&from;=appmsg)

创建工作区就可以直接对话了

![](https://mmbiz.qpic.cn/sz_mmbiz_png/BXJXNRRKQNKdP8mQcfmdFrLZ9xFcvvwrQ24vdQYK8FpJSrrcv7NsyzNPAY9YuGIOe5d5bgAC650OWs0lGl9oHQ/640?wx_fmt=png&from;=appmsg)![](https://mmbiz.qpic.cn/sz_mmbiz_png/BXJXNRRKQNKdP8mQcfmdFrLZ9xFcvvwricotlMWLxU4FQy4wNGYHicvatxnEnelic1g5OKNE2wQMicL2yk6ibXTOaVg/640?wx_fmt=png&from;=appmsg)

直接创建工作区，就能对话回答，让它写程序回答也快

![](https://mmbiz.qpic.cn/sz_mmbiz_png/BXJXNRRKQNKdP8mQcfmdFrLZ9xFcvvwrRSYMuorndS2sTicCTRd8aobOxW0ETnam73vbdQxvpRvsGL9wR0iapKbQ/640?wx_fmt=png&from;=appmsg)

点击这个上传按钮，可以上传我们的本地文档作为知识库

![](https://mmbiz.qpic.cn/sz_mmbiz_png/BXJXNRRKQNKdP8mQcfmdFrLZ9xFcvvwrnKzcMaTRFjy6AuRolHFibNyGMFn0XzfMKGJhD1C3TKUOib7qf8vBjV3w/640?wx_fmt=png&from;=appmsg)

不过目前小懒对于本地知识库的训练结果还不是特别满意，当时小懒想的是，把记忆承载三千多篇推文，都喂给他，做一个AI西风，后面接入吹水群

![](https://mmbiz.qpic.cn/sz_mmbiz_png/BXJXNRRKQNKdP8mQcfmdFrLZ9xFcvvwrdbJzcTk9RUiapU1wDIvOVTH2hibFRADibBMWR9gicqTxQCVV6JAwia0YbzQ/640?wx_fmt=png&from;=appmsg)

可是，接入本地知识库后，回答却出错——应该是本地向量没建立好

![](https://mmbiz.qpic.cn/sz_mmbiz_png/BXJXNRRKQNKdP8mQcfmdFrLZ9xFcvvwrib8PufIEsXZaOaz1wE89nzvompopdUJa1qTkPzXSburG4ylqTKnlsuQ/640?wx_fmt=png&from;=appmsg)

网上也说知识库正确率一般，所以后面应该还需要进行微调

大家可以把它作为自己的一个本地AI，比如一些国有单位，对于资料监管比较严格，或者不方便联网等等

甚至沉浸式翻译都可以调用这个API

## 补充

Ollama的大模型默认下到C盘，对空间占用比较大

如果想要换到其他盘的话，见下图AI的解答

![](https://mmbiz.qpic.cn/sz_mmbiz_png/BXJXNRRKQNKdP8mQcfmdFrLZ9xFcvvwrVcdhCqW85sS30ZAX8PJib0kgAtryPQyibQEticx6F6bdqPAicA8bQODdxg/640?wx_fmt=png&from;=appmsg)

迁移模型位置的话，见下图方法

![](https://mmbiz.qpic.cn/sz_mmbiz_png/BXJXNRRKQNKdP8mQcfmdFrLZ9xFcvvwrfFvU1CdicQs5ibuxUmZIuUHkEEIvJ4zW7eKYtUcoRbwXhCV4LYBV64RA/640?wx_fmt=png&from;=appmsg)

另外，本地大模型比较数据量有限，其实回答的精度和智能化远不如在线那些大厂AI

如果不是担心数据云端泄露，只能离线大模型。或者打算自建知识库的话，建议大家可以用在线AI平台，这篇文章点赞过十个，找时间汇总一下现在的AI写作工具吧

![](https://mmbiz.qpic.cn/sz_mmbiz_png/BXJXNRRKQNKdP8mQcfmdFrLZ9xFcvvwr7aVqy1IV6jBahcS5bOqBD1bPZBXV0OyeAzvsfEXIkoniauNzwcUVJpA/640?wx_fmt=png&from;=appmsg)

## 资源领取

今天分享的Ollama和Anythin LLM都可以官网下载，文中有附

不过小懒还在在后台准备了一份软件压缩包

本公众号后台回复 241218 领取资源地址

![](https://mmbiz.qpic.cn/sz_mmbiz_png/BXJXNRRKQNLUDREWLEiaz4atNIu5GsH65E1SdqC8k1gMylFg91guwoqWCY4QcABnbsh9RIz8Un8iaGSr9OPfQhXA/640?wx_fmt=png&wxfrom;=5&wx;_lazy=1&wx;_co=1)

## 题外话

这两周给[懒人专属群](https://mp.weixin.qq.com/s?__biz=MzkwNjE5NDYzOQ==&mid=2247493087&idx=1&sn=e147d983c4441e296ee9b0ae0cdf5716&scene=21#wechat_redirect)整理的副业周刊和风向标，看到很多编程小白利用AI编程Cursor写出来很多软件

比如这是一个小白利用cursor做的图片压缩网站

![](https://mmbiz.qpic.cn/sz_mmbiz_png/BXJXNRRKQNKdP8mQcfmdFrLZ9xFcvvwrq2EcZE6GBCxCkXSiapI3OK5Hva7PHiaePWmuoHO4c8qP6U8Cg7wicwaCw/640?wx_fmt=png&from;=appmsg)

AI编程让创意更快成为成果

以前有个梗叫“就差一个程序员”了，现在这个技术护城河，也因为AI减弱不少

附上新手接触Cursor的几个问题：

![](https://mmbiz.qpic.cn/sz_mmbiz_png/BXJXNRRKQNKdP8mQcfmdFrLZ9xFcvvwrwbpCczFaBAR7Aicib7aic7Vv6Lkwx04l7eLeiaZXDLfeyOAcIgRPibvykuw/640?wx_fmt=png&from;=appmsg)

## 懒人专属群

[懒人专属群](https://mp.weixin.qq.com/s?__biz=MzkwNjE5NDYzOQ==&mid=2247493087&idx=1&sn=e147d983c4441e296ee9b0ae0cdf5716&scene=21#wechat_redirect)继续纳新，欢迎需要的Bro加入组织

![](https://mmbiz.qpic.cn/sz_mmbiz_png/BXJXNRRKQNL2TXGXG4RpnR4Oa6BBiaMafcicNzVIMy2BZagKPXf95Tj9OCNzdtlyxqluSfibjAlOCejsg2rXxJ18A/640?wx_fmt=png&from;=appmsg&wxfrom;=5&wx;_lazy=1&wx;_co=1)

识别查看更新记录：

![](https://mmbiz.qpic.cn/sz_mmbiz_png/BXJXNRRKQNJsz63cfklUia8jpvia2WCF5CChSaJTbagddbfEOv4lUhaJJuZ1DwET6L8nyECznicEkBzQeT0fmgTEA/640?wx_fmt=other&from;=appmsg&tp;=webp&wxfrom;=5&wx;_lazy=1&wx;_co=1)

  

左拉标签公众号懒人搜索，懒人专属群介绍[](https://mp.weixin.qq.com/s?__biz=MzkwNjE5NDYzOQ==&mid=2247493087&idx=1&sn=e147d983c4441e296ee9b0ae0cdf5716&scene=21#wechat_redirect)

***公众号懒人搜索 | 手机端访问查看完整样式 | 标签可以向左拖拽，来回拖动**

  

##  今日一言

> 我没有感觉到绝望，也没有感觉到希望，我告诫自己不要以现在的心情去规定未来。
>
> ——片山恭一

![](https://mmbiz.qpic.cn/sz_mmbiz_jpg/BXJXNRRKQNKdP8mQcfmdFrLZ9xFcvvwrhsCpPxfPeNq6re24WQ1barknzPnZR0Z1nQXowKoPlNygar4AG1iaxSQ/640?wx_fmt=jpeg&from;=appmsg)

## 推荐阅读

[再见了，IDM](https://mp.weixin.qq.com/s?__biz=MzkwNjE5NDYzOQ==&mid=2247494201&idx=1&sn=9335e8ca2283b7698bd663f151e6d054&token=550343844&lang=zh_CN&scene=21#wechat_redirect)

[又一极品软件，免费无限制！](https://mp.weixin.qq.com/s?__biz=MzkwNjE5NDYzOQ==&mid=2247494183&idx=1&sn=6147d817558e61120ed5d4f03c1c3bed&token=550343844&lang=zh_CN&scene=21#wechat_redirect)

[真的要这么快吗？](https://mp.weixin.qq.com/s?__biz=MzkwNjE5NDYzOQ==&mid=2247494159&idx=1&sn=6871d5cb7847f1333286b07f3075c936&token=1531965592&lang=zh_CN&scene=21#wechat_redirect)

[遭全网下架，最后的“专业版本”](https://mp.weixin.qq.com/s?__biz=MzkwNjE5NDYzOQ==&mid=2247494086&idx=1&sn=c51f5c98ed5bf237a91ff733da146dd4&token=1225813664&lang=zh_CN&poc_token=HNXzV2ej6DmKZPOBvSSCa18lWxPY0s67aIq419po&scene=21#wechat_redirect)

[神级“下崽器”，支持多平台！](https://mp.weixin.qq.com/s?__biz=MzkwNjE5NDYzOQ==&mid=2247494067&idx=1&sn=46547841d3f722fb8c2e663fc9886f3e&token=379587468&lang=zh_CN&scene=21#wechat_redirect)

[](https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzkwNjE5NDYzOQ==&action=getalbum&album_id=3095199290177650691#wechat_redirect)[](https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzkwNjE5NDYzOQ==&action=getalbum&album_id=3184635951063531523#wechat_redirect)[](https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzkwNjE5NDYzOQ==&action=getalbum&album_id=3189384915092537344#wechat_redirect)[](https://mp.weixin.qq.com/mp/appmsgalbum?__biz=MzkwNjE5NDYzOQ==&action=getalbum&album_id=3095199290177650691#wechat_redirect)如页面未加载，请刷新重试

***公众号懒人搜索 | 点击跳转专题 | 欢迎订阅**

> 如果你喜欢小懒的推文，希望可以把公众号文章分享出去
>
> 你的支持很重要~

![](https://mmbiz.qpic.cn/sz_mmbiz_gif/BXJXNRRKQNJ6YdLcSex3A3fRP26rl1cS3HO7V1sQUXcdiakzhwpgs1FicmG6XVSr6w6VRhSpuiagjCk1UcMxSbSdg/640?wx_fmt=gif&from;=appmsg)

  

